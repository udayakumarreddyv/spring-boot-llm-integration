spring:
  application:
    name: llm-integration-service-dev
  
server:
  port: 8080

# Development LLM Provider Configurations
llm:
  providers:
    openai:
      enabled: false  # Set to true and add your API key to test
      base-url: "https://api.openai.com/v1"
      api-key: "${OPENAI_API_KEY:your-openai-api-key-here}"
      default-model: "gpt-3.5-turbo"
      timeout: 30000
      
    anthropic:
      enabled: false  # Set to true and add your API key to test
      base-url: "https://api.anthropic.com/v1"
      api-key: "${ANTHROPIC_API_KEY:your-anthropic-api-key-here}"
      default-model: "claude-3-sonnet-20240229"
      timeout: 30000
      
    ollama:
      enabled: true   # Enabled by default for local development
      base-url: "http://localhost:11434/v1"
      api-key: "ollama"
      default-model: "llama2"
      timeout: 60000
      
    azure-openai:
      enabled: false
      base-url: "${AZURE_OPENAI_ENDPOINT:your-azure-endpoint-here}"
      api-key: "${AZURE_OPENAI_API_KEY:your-azure-api-key-here}"
      default-model: "gpt-35-turbo"
      timeout: 30000
      
    huggingface:
      enabled: false
      base-url: "https://api-inference.huggingface.co/models"
      api-key: "${HUGGINGFACE_API_KEY:your-huggingface-api-key-here}"
      default-model: "microsoft/DialoGPT-medium"
      timeout: 30000

  # Global settings for development
  default-provider: "ollama"
  max-tokens: 500
  temperature: 0.7
  stream: false

# Actuator configuration for development
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,env,configprops
  endpoint:
    health:
      show-details: always

# Development logging
logging:
  level:
    com.example.llm: DEBUG
    org.springframework.web: INFO
    org.springframework.web.reactive.function.client: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
